---
layout: default
title: Home
---

<div class="hero-section">
    <img src="{{ '/assets/images/resume.jpg' | relative_url }}" alt="Haolin Yang" class="hero-avatar">
    <h1 class="hero-name">Haolin Yang</h1>
    <p class="hero-name-cn">æ¨ æ˜Š éœ–</p>
    <p class="hero-title">
        <i class="fas fa-graduation-cap"></i> åŒ—äº¬å¤§å­¦ Â· æ™ºèƒ½ç§‘å­¦ä¸æŠ€æœ¯ä¸“ä¸š æœ¬ç§‘ç”Ÿ
    </p>
    <div class="hero-links">
        <a href="mailto:your_email@pku.edu.cn" class="hero-link">
            <i class="fas fa-envelope"></i>
            Email
        </a>
        <a href="https://github.com/tidalharley" target="_blank" class="hero-link">
            <i class="fab fa-github"></i>
            GitHub
        </a>
        <a href="{{ '/cv' | relative_url }}" class="hero-link">
            <i class="fas fa-file-alt"></i>
            CV
        </a>
        <a href="https://scholar.google.com" target="_blank" class="hero-link">
            <i class="fas fa-graduation-cap"></i>
            Google Scholar
        </a>
    </div>
</div>

---

## <i class="fas fa-user"></i> About Me

I am a third-year undergraduate student at **Peking University**, majoring in **Intelligence Science and Technology**. My research focuses on building intelligent agents that can understand and navigate the physical world through language and vision.

Currently, I am working on:

<div class="research-interests">
    <span class="interest-tag"><i class="fas fa-robot"></i> Embodied AI</span>
    <span class="interest-tag"><i class="fas fa-route"></i> Vision-Language Navigation</span>
    <span class="interest-tag"><i class="fas fa-brain"></i> Spatial Intelligence</span>
    <span class="interest-tag"><i class="fas fa-layer-group"></i> Multimodal Learning</span>
</div>

I have built **NavSpace**, a comprehensive benchmark for evaluating the spatial intelligence of navigation agents, featuring 1200+ trajectories across six major categories of spatial reasoning abilities.

---

## <i class="fas fa-newspaper"></i> News

<div class="news-timeline">
    <div class="news-item">
        <span class="news-date">2025.11</span>
        <p class="news-content">ğŸ¯ Continuing development of NavSpace benchmark with enhanced spatial reasoning tasks.</p>
    </div>
    <div class="news-item">
        <span class="news-date">2025.09</span>
        <p class="news-content">ğŸ“Š Completed data collection: 1200+ navigation trajectories and instructions collected.</p>
    </div>
    <div class="news-item">
        <span class="news-date">2024.12</span>
        <p class="news-content">ğŸ”¬ Started Sim2Sim evaluation of VLNCE models on HM3D environments.</p>
    </div>
    <div class="news-item">
        <span class="news-date">2024.06</span>
        <p class="news-content">ğŸš€ Initiated NavSpace project - A benchmark for spatial intelligence in navigation.</p>
    </div>
</div>

---

## <i class="fas fa-star"></i> Featured Research

<div class="project-grid">
    <div class="project-card">
        <div class="project-header">
            <h3 class="project-title">NavSpace Benchmark</h3>
            <span class="project-status">In Progress</span>
        </div>
        <p class="project-description">
            A comprehensive benchmark for evaluating the <strong>spatial intelligence</strong> of navigation agents. NavSpace systematically tests agents' abilities in spatial reasoning, including distance estimation, direction understanding, object relationships, and route planning.
        </p>
        <div class="project-stats">
            <div class="stat-item">
                <span class="stat-value">1200+</span>
                <span class="stat-label">Trajectories</span>
            </div>
            <div class="stat-item">
                <span class="stat-value">6</span>
                <span class="stat-label">Ability Categories</span>
            </div>
            <div class="stat-item">
                <span class="stat-value">HM3D</span>
                <span class="stat-label">Environment</span>
            </div>
        </div>
        <div class="project-tags">
            <span class="project-tag">VLN</span>
            <span class="project-tag">Spatial Reasoning</span>
            <span class="project-tag">Benchmark</span>
        </div>
    </div>
</div>

<p class="text-center mt-lg">
    <a href="{{ '/projects' | relative_url }}" class="hero-link">
        <i class="fas fa-arrow-right"></i>
        æŸ¥çœ‹å…¨éƒ¨é¡¹ç›®
    </a>
</p>

---

## <i class="fas fa-search"></i> Research Interests

<div class="content-card">
    <div class="card-icon">
        <i class="fas fa-robot"></i>
    </div>
    <h4>Embodied AI & Navigation</h4>
    <p>Developing intelligent agents that can navigate complex 3D environments using natural language instructions. Focusing on Vision-and-Language Navigation (VLN) tasks in realistic indoor environments like HM3D and Matterport3D.</p>
</div>

<div class="content-card">
    <div class="card-icon">
        <i class="fas fa-brain"></i>
    </div>
    <h4>Spatial Intelligence</h4>
    <p>Understanding and evaluating how AI agents perceive and reason about spatial relationships. Building systematic benchmarks to measure spatial reasoning capabilities across multiple dimensions.</p>
</div>

<div class="content-card">
    <div class="card-icon">
        <i class="fas fa-layer-group"></i>
    </div>
    <h4>Multimodal Learning</h4>
    <p>Exploring the intersection of vision and language in AI systems. Interested in how large multimodal models can be applied to embodied tasks and real-world scenarios.</p>
</div>

---

## <i class="fas fa-lightbulb"></i> Beyond Research

I believe that great research should not only advance scientific understanding but also have the potential to transform how people interact with technology in their daily lives.
